# Backend environment variables
# Copy this file to .env and fill in your Supabase credentials

# Frontend origin for CORS
FRONTEND_ORIGIN=http://localhost:5173

# Supabase project
SUPABASE_URL=https://<your-project-ref>.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOi...<anon>
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOi...<service_role>

# Storage bucket for documents
SUPABASE_STORAGE_BUCKET=documents

# Debug flag
DEBUG=false

# # ===== RAG (optional, all local and free) =====
# # Where to persist ChromaDB index (will be created if missing)
# RAG_STORE_DIR=./rag_store
# # Embedding model name for sentence-transformers
# RAG_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
# # Ollama model (if you have Ollama installed). If not set, fallback to extractive answer.
# OLLAMA_MODEL=llama3.1:8b

RAG_STORE_BACKEND=supabase #để lưu trên Supabase pgvector
RAG_STORE_BACKEND=chroma #mặc định, lưu local

EMBED_PROVIDER=openai #openai | gemini | local
LLM_PROVIDER=openai #openai | gemini | ollama | none

## Nếu OpenAI
OPENAI_API_KEY=sk-<your-api-key>
OPENAI_EMBED_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-4o-mini

## Nếu Gemini
GEMINI_API_KEY=AIzaSy...<your-api-key>
GEMINI_EMBED_MODEL=models/text-embedding-004
GEMINI_CHAT_MODEL=gemini-1.5-flash

## Nếu Ollama
OLLAMA_API_KEY=sentence-transformers/all-MiniLM-L6-v2
OLLAMA_MODEL=none #hoặc ollama

RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=80